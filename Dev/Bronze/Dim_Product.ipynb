{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c9af90e-b232-4cd0-98c1-cfb3d71db863",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install --upgrade dbldatagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be80dc3c-b8f5-43f2-b411-81a7d9b61fc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------------\n",
    "# CONFIG & WIDGETS\n",
    "# ---------------------------------------------\n",
    "spark.sql(\"USE CATALOG dev\")\n",
    "db_name = \"dev.bronze\"\n",
    "table_name = \"dim_product\"\n",
    "full_table_name = f\"{db_name}.{table_name}\"\n",
    "\n",
    "# Batch date (YYYY-MM-DD) for deterministic daily generation\n",
    "\n",
    "from pyspark.sql import functions as F, Window\n",
    "from datetime import date\n",
    "as_of_date_col = F.current_date()  \n",
    "as_of_date_str = date.today().isoformat()  \n",
    "\n",
    "# Synthetic generation controls\n",
    "MODELS_PER_BRAND_ITEM_BASE = 3       # core models per (brand,item)\n",
    "NEW_MODELS_PER_BRAND_ITEM = 3      # new models introduced daily\n",
    "DAILY_PRICE_CHANGE_RATE = 0.30       # 30% of models get price changes daily\n",
    "MODEL_PRICE_SPREAD_PCT = 0.15        # +/-15% spread around brand+item baseline\n",
    "DAILY_DRIFT_PCT = 0.05               # +/-5% daily drift for changing models\n",
    "\n",
    "GST_RATE = 0.18\n",
    "FUTURE_DATE = \"2099-12-31\"\n",
    "\n",
    "# ---------------------------------------------\n",
    "# IMPORTS\n",
    "# ---------------------------------------------\n",
    "import dbldatagen as dg\n",
    "import random\n",
    "import hashlib\n",
    "\n",
    "# Seed random deterministically by date\n",
    "seed_val = int(hashlib.sha256((as_of_date_str or str(F.current_date())).encode(\"utf-8\")).hexdigest(), 16) % (10**8)\n",
    "random.seed(seed_val)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# DOMAIN: categories, items, brands\n",
    "# ---------------------------------------------\n",
    "name_to_category = {\n",
    "    \"Electronics\": {\"items\": [\"Mobiles\", \"Laptops\"]},\n",
    "    \"Appliances\": {\"items\": [\"Refrigerators\", \"Washing Machines\"]},\n",
    "    \"Clothing\": {\"items\": [\"Jeans\", \"Shoes\"]}\n",
    "}\n",
    "\n",
    "brands_by_category = {\n",
    "    \"Electronics\": [\"Apple\", \"Samsung\", \"Dell\", \"Lenovo\", \"ASUS\"],\n",
    "    \"Appliances\": [\"LG\", \"Samsung\", \"Whirlpool\"],\n",
    "    \"Clothing\": [\"Levi's\", \"Nike\", \"Adidas\", \"Puma\"]\n",
    "}\n",
    "\n",
    "# Baseline price by (brand, item) for realistic ranges (INR)\n",
    "price_by_brand_item = {\n",
    "    # Electronics\n",
    "    (\"Apple\", \"Mobiles\"): 90000,\n",
    "    (\"Samsung\", \"Mobiles\"): 45000,\n",
    "    (\"Lenovo\", \"Laptops\"): 55000,\n",
    "    (\"ASUS\", \"Laptops\"): 60000,\n",
    "    (\"Dell\", \"Laptops\"): 70000,\n",
    "\n",
    "    # Appliances\n",
    "    (\"LG\", \"Refrigerators\"): 60000,\n",
    "    (\"Samsung\", \"Refrigerators\"): 65000,\n",
    "    (\"Whirlpool\", \"Refrigerators\"): 40000,\n",
    "    (\"LG\", \"Washing Machines\"): 32000,\n",
    "    (\"Samsung\", \"Washing Machines\"): 35000,\n",
    "\n",
    "    # Clothing\n",
    "    (\"Levi's\", \"Jeans\"): 3800,\n",
    "    (\"Nike\", \"Shoes\"): 9000,\n",
    "    (\"Adidas\", \"Shoes\"): 8000,\n",
    "    (\"Puma\", \"Shoes\"): 5000\n",
    "}\n",
    "\n",
    "# Optional core series names to make models look realistic\n",
    "core_series = {\n",
    "    # Electronics\n",
    "    (\"Apple\", \"Mobiles\"): [\"iPhone 15\", \"iPhone 15 Pro\", \"iPhone SE\"],\n",
    "    (\"Samsung\", \"Mobiles\"): [\"Galaxy S23\", \"Galaxy A54\", \"Galaxy M34\"],\n",
    "    (\"Dell\", \"Laptops\"): [\"XPS 13\", \"Inspiron 15\", \"G15\"],\n",
    "    (\"Lenovo\", \"Laptops\"): [\"ThinkPad X1\", \"IdeaPad Slim 5\", \"Legion 5\"],\n",
    "    (\"ASUS\", \"Laptops\"): [\"ZenBook 14\", \"VivoBook 15\", \"ROG Strix G16\"],\n",
    "\n",
    "    # Appliances\n",
    "    (\"LG\", \"Refrigerators\"): [\"InstaView\", \"Side-by-Side 687L\", \"Frost Free 360L\"],\n",
    "    (\"Samsung\", \"Refrigerators\"): [\"Family Hub\", \"Side-by-Side 700L\", \"Frost Free 345L\"],\n",
    "    (\"Whirlpool\", \"Refrigerators\"): [\"IntelliFresh 340L\", \"Double Door 265L\"],\n",
    "    (\"LG\", \"Washing Machines\"): [\"Front Load 8kg (AI DD)\", \"Top Load 7kg\", \"Washer Dryer 9/6kg\"],\n",
    "    (\"Samsung\", \"Washing Machines\"): [\"EcoBubble 8kg\", \"Hygiene Steam 7.5kg\", \"AddWash 9kg\"],\n",
    "\n",
    "    # Clothing\n",
    "    (\"Levi's\", \"Jeans\"): [\"511 Slim\", \"512 Slim Taper\", \"501 Original\", \"541 Athletic\"],\n",
    "    (\"Nike\", \"Shoes\"): [\"Air Force 1\", \"Air Max 270\", \"Revolution 6\"],\n",
    "    (\"Adidas\", \"Shoes\"): [\"Stan Smith\", \"Ultraboost\", \"Duramo SL\"],\n",
    "    (\"Puma\", \"Shoes\"): [\"Smash v2\", \"RS-X\", \"Carson Runner\"]\n",
    "}\n",
    "\n",
    "# ---------------------------------------------\n",
    "# HELPERS: synthetic model & price generation\n",
    "# ---------------------------------------------\n",
    "def make_new_model_name(brand: str, item: str, idx: int, date_str: str) -> str:\n",
    "    \"\"\"Generate a 'new' model name that varies by date to simulate new product arrivals.\"\"\"\n",
    "    suffix = date_str.replace(\"-\", \"\") if date_str else \"today\"\n",
    "    return f\"{brand} {item} {suffix}-{idx}\"\n",
    "\n",
    "def model_price_from_baseline(baseline: float, model_name: str) -> float:\n",
    "    \"\"\"Make a stable per-model price around baseline using hash-based offset.\"\"\"\n",
    "    # Stable offset per model within +/- MODEL_PRICE_SPREAD_PCT\n",
    "    h = int(hashlib.sha256(model_name.encode(\"utf-8\")).hexdigest(), 16) % 10000\n",
    "    frac = (h / 10000.0 - 0.5) * 2.0  # in [-1, +1]\n",
    "    spread = MODEL_PRICE_SPREAD_PCT * frac\n",
    "    return max(1.0, round(baseline * (1 + spread), 2))\n",
    "\n",
    "def maybe_apply_daily_drift(price: float) -> float:\n",
    "    \"\"\"Apply daily drift to a subset of models based on DAILY_PRICE_CHANGE_RATE.\"\"\"\n",
    "    if random.random() < DAILY_PRICE_CHANGE_RATE:\n",
    "        drift_frac = (random.random() * 2 - 1) * DAILY_DRIFT_PCT  # [-DRIFT, +DRIFT]\n",
    "        price = price * (1 + drift_frac)\n",
    "    return round(price, 2)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# SYNTHETIC DAILY DATA GENERATION\n",
    "# ---------------------------------------------\n",
    "records = []\n",
    "date_str = as_of_date_str or \"TODAY\"\n",
    "\n",
    "for category, info in name_to_category.items():\n",
    "    items = info.get(\"items\", [])\n",
    "    category_brands = brands_by_category.get(category, [])\n",
    "    for item in items:\n",
    "        for brand in category_brands:\n",
    "            # Baseline price for brand+item\n",
    "            baseline = price_by_brand_item.get((brand, item), 10000)\n",
    "\n",
    "            # 1) Core models\n",
    "            core = core_series.get((brand, item), [])\n",
    "            core_models = core[:MODELS_PER_BRAND_ITEM_BASE] if core else []\n",
    "            # If fewer core names than base count, synthesize extra\n",
    "            while len(core_models) < MODELS_PER_BRAND_ITEM_BASE:\n",
    "                core_models.append(make_new_model_name(brand, item, len(core_models) + 1, \"BASE\"))\n",
    "\n",
    "            # 2) New models for the day\n",
    "            new_models = [make_new_model_name(brand, item, i + 1, date_str) for i in range(NEW_MODELS_PER_BRAND_ITEM)]\n",
    "\n",
    "            # Combine\n",
    "            all_models = core_models + new_models\n",
    "\n",
    "            # Prices per model\n",
    "            for model in all_models:\n",
    "                base_price = model_price_from_baseline(baseline, model)  # per-model stable price\n",
    "                final_price = maybe_apply_daily_drift(base_price)        # daily change for some models\n",
    "                records.append({\n",
    "                    \"category\": category,\n",
    "                    \"name\": item,\n",
    "                    \"brand\": brand,\n",
    "                    \"model\": model,\n",
    "                    \"Price\": float(final_price)\n",
    "                })\n",
    "\n",
    "# Create daily DF\n",
    "df_daily = spark.createDataFrame(records)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# ENRICH: currency, GST, effective dates, is_current\n",
    "# ---------------------------------------------\n",
    "df_src = (\n",
    "    df_daily\n",
    "    .withColumn(\"currency\", F.lit(\"INR\"))\n",
    "    .withColumn(\"gst_rate\", F.lit(GST_RATE))\n",
    "    .withColumn(\"price_incl_gst\", F.round(F.col(\"Price\") * (1 + F.col(\"gst_rate\")), 2))\n",
    "    .withColumn(\"effective_from\", as_of_date_col)\n",
    "    .withColumn(\"effective_to\", F.to_date(F.lit(FUTURE_DATE)))\n",
    "    .withColumn(\"is_current\", F.lit(True))\n",
    ")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# IDs: stable product_id (hash of natural key), new product_sk per version\n",
    "# ---------------------------------------------\n",
    "natural_key_cols = [\"category\", \"name\", \"brand\", \"model\"]\n",
    "\n",
    "# Read current max product_sk\n",
    "exists = spark.catalog.tableExists(full_table_name)\n",
    "if exists:\n",
    "    max_sk_val = (\n",
    "        spark.table(full_table_name)\n",
    "        .agg(F.max(\"product_sk\").alias(\"max_sk\"))\n",
    "        .collect()[0][\"max_sk\"]\n",
    "    )\n",
    "    max_sk = int(max_sk_val) if max_sk_val is not None else 0\n",
    "else:\n",
    "    max_sk = 0\n",
    "\n",
    "# Allocate new product_sk for each row\n",
    "num_rows = df_src.count()\n",
    "dg_spec = (\n",
    "    dg.DataGenerator(spark, rows=num_rows, partitions=8)\n",
    "    .withIdOutput()\n",
    "    .withColumn(\"product_id\", \"string\", expr=\"concat('PID-', cast(id as string))\")\n",
    "    .withColumn(\"product_sk\", \"long\", expr=f\"id + {max_sk} + 1\")\n",
    ")\n",
    "df_ids = dg_spec.build().select(\"id\", \"product_id\", \"product_sk\")\n",
    "\n",
    "# Deterministic alignment via row_number\n",
    "w_ids = Window.orderBy(F.col(\"id\"))\n",
    "df_ids = df_ids.withColumn(\"rn\", F.row_number().over(w_ids))\n",
    "w_src = Window.orderBy(F.monotonically_increasing_id())\n",
    "df_src = df_src.withColumn(\"rn\", F.row_number().over(w_src))\n",
    "\n",
    "df_src = df_src.join(df_ids, on=\"rn\", how=\"inner\").drop(\"rn\", \"id\")\n",
    "\n",
    "df_src.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "656f1940-0a7e-4826-a51e-e8971e74ec0e",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1767266651235}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {full_table_name} (\n",
    "    product_sk BIGINT,\n",
    "    product_id STRING,\n",
    "    category STRING,\n",
    "    name STRING,\n",
    "    brand STRING,\n",
    "    model STRING,\n",
    "    Price DOUBLE,\n",
    "    currency STRING,\n",
    "    gst_rate DOUBLE,\n",
    "    price_incl_gst DOUBLE,\n",
    "    effective_from DATE,\n",
    "    effective_to DATE,\n",
    "    is_current BOOLEAN\n",
    ")\n",
    "USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# OPTIONAL: idempotency cleanup for the same as_of_date\n",
    "# ---------------------------------------------\n",
    "if as_of_date_str:\n",
    "    spark.sql(f\"DELETE FROM {full_table_name} WHERE effective_from = DATE('{as_of_date_str}')\")\n",
    "\n",
    "\n",
    "desired_order = [\n",
    "    \"product_sk\",\n",
    "    \"product_id\",\n",
    "    \"category\",\n",
    "    \"name\",\n",
    "    \"brand\",\n",
    "    \"model\",\n",
    "    \"Price\",\n",
    "    \"currency\",\n",
    "    \"gst_rate\",\n",
    "    \"price_incl_gst\",\n",
    "    \"effective_from\",\n",
    "    \"effective_to\",\n",
    "    \"is_current\"\n",
    "]\n",
    "\n",
    "\n",
    "# Register source view\n",
    "df_src.createOrReplaceTempView(\"src_dim_product\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# SCD TYPE 2 MERGE: close previous current row on change, insert new version\n",
    "# ---------------------------------------------\n",
    "spark.sql(f\"\"\"\n",
    "MERGE INTO {full_table_name} AS tgt\n",
    "USING src_dim_product AS src\n",
    "ON  tgt.category = src.category\n",
    "AND tgt.name     = src.name\n",
    "AND tgt.brand    = src.brand\n",
    "AND tgt.model    = src.model\n",
    "AND tgt.is_current = TRUE\n",
    "\n",
    "WHEN MATCHED AND (\n",
    "       tgt.Price          <> src.Price\n",
    "    OR tgt.currency       <> src.currency\n",
    "    OR tgt.gst_rate       <> src.gst_rate\n",
    "    OR tgt.price_incl_gst <> src.price_incl_gst\n",
    ") THEN\n",
    "  UPDATE SET\n",
    "      tgt.effective_to = date_add(src.effective_from, -1),\n",
    "      tgt.is_current   = FALSE\n",
    "\n",
    "WHEN NOT MATCHED THEN\n",
    "  INSERT (\n",
    "      product_sk,\n",
    "      product_id,\n",
    "      category,\n",
    "      name,\n",
    "      brand,\n",
    "      model,\n",
    "      Price,\n",
    "      currency,\n",
    "      gst_rate,\n",
    "      price_incl_gst,\n",
    "      effective_from,\n",
    "      effective_to,\n",
    "      is_current\n",
    "  )\n",
    "  VALUES (\n",
    "      src.product_sk,\n",
    "      src.product_id,\n",
    "      src.category,\n",
    "      src.name,\n",
    "      src.brand,\n",
    "      src.model,\n",
    "      src.Price,\n",
    "      src.currency,\n",
    "      src.gst_rate,\n",
    "      src.price_incl_gst,\n",
    "      src.effective_from,\n",
    "      src.effective_to,\n",
    "      src.is_current\n",
    "  )\n",
    "\"\"\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# PREVIEW\n",
    "# ---------------------------------------------\n",
    "display(\n",
    "    spark.table(full_table_name).select(*desired_order)\n",
    "         .orderBy(\"category\", \"name\", \"brand\", \"model\", \"effective_from\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d7ebefe-022c-4c20-a267-32281f4a511d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select count(*) from dev.bronze.dim_product"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7886270424605642,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Dim_Product",
   "widgets": {
    "as_of_date": {
     "currentValue": "",
     "nuid": "907a98c0-da33-4c27-aab4-61d5b924c804",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "as_of_date",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "as_of_date",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
